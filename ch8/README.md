## 8.1 agent基础：

### tips：

在组会中听了硕士生师兄的暑假成果汇报后发现自己对于LLM agent还不是非常熟悉，虽说不一定是研究这个方向，但需要至少有所了解。

### 问题:

除去像无人驾驶这样的带有反馈规划的智能体，感觉在使用AIGC时见到的最多的所谓大模型智能体实际上就是，先基于提示词给大模型一段上下文，规定以下其回答的方式和风格。然后开始类似于角色扮演一样，例如医疗专家，专业会计，前端工程师之类的。其相比于直接向通用的大模型提问，然后自己去设置提示词，使用agent的好处在哪里？

* 直接提示（Prompt） = 一次性的角色设定，结果靠用户自己控制。
* 智能体（Agent） = 在角色设定的基础上，加入了记忆、任务分解、工具使用、自动迭代，可以更自主地完成复杂任务。

## 8.2 8.3 大模型智能体架构和训练：

### 思考：

* 推理规划中提到可以使用思维链提示来提高大模型的推理能力，现在再看，有点类似于prompt工程，但实际上这是从不同粒度的角度来调用大模型，让其去模仿人类思考的方式，从而使得问题的解决可以不再是直接一步到位而是拆分成多个小的问题。模型可以在更细粒度的层面上去解决这些被拆分的问题，然后再将其汇总和合并得到粗粒度层面上问题的解，从而提升推理能力。
* 看到关于大模型智能体长期记忆的部分，提到了遗忘机制，刚好老师在组会中也提到了遗忘机制。MemoryBank借鉴了艾宾浩斯遗忘曲线，从其他的学科得到的灵感来模仿人类的记忆机制。从单个聊天中的不同prompt或是不同话题的聊天中获取关键的信息进行记忆从而做到对用户的使用风格进行更精准的把握，生成更个性化的回答。

### tips：

思考中的记忆功能目前在多个AIGC上有已经被广泛应用。eg：gpt和gemini都会通过了解最近的几次聊天来优化新的话题的回答来作为个性化的一个实用方法

