### 第二章：

在这一章系统性学习了Transformer架构，大大加深了我对Transformer的理解，基本能够完成对源代码逐字逐句的理解。同时也学习了GPT和llama的结构，对这些基于Transformer架构的模型有了更好的认知。也学了包括MOE和稀疏注意力机制等对Transformer的优化的一些方法和机制。这一章书里讲得很清楚并且配套的代码也是最相关的，感觉这一章学下来很有用，扎实的学到东西了。

### 第三章：

介绍了大模型预训练的数据的处理方法，这里主要是学会了BPE的分词方法。同时还从宏观上了解了训练数据对大模型性能的影响和一些被广泛认可的预训练数据集。这一章读起来比较"空",相对来说没有像上一章那么具体，实验也是只完成了对BPE算法的复现。这章看完感觉就是稍微了解了预训练数据的处理方式。

### 第五章：

学习了指令微调的完整流程和作用。重点看了Lora微调，对其原理我还尝试从线性代数的底层逻辑去理解。但对模型上下文窗口的拓展还未理解。实验上尝试了对原有的示例实验的改进，最后还是成功了，算是对deepmind框架学习的一大收获。这一章学习后感觉对Lora的理解大大加深了，并且有了实践的经验。

### 第六章：

这章的理论性非常强，有很多强化学习的推导公式，出于时间原因，这些公式我只是看了个半懂，有些还不能理解的就先按着不动，先往下看了。但总体上还是对强化学习的整体架构相比于之前有了一个清晰的认知。同时也结合自己频繁使用LLM的经验去探讨了aha moment的原理，和推理时思维链的作用。并且认真学习了RLHF的流程和原理，对我之前大创时的DPO项目的实践有了更理论的认知，实验上也去尝试复现verl，但因为是一个小众的框架，并且需要多卡GPU，在多次配置环境和对多卡改单卡等等的设置尝试修改后仍然报错，最后无果。读这一章让我有一种顿悟和醍醐灌顶的感觉，我终于算是更清楚地弄明白了自己之前的sitp项目的理论原理，有一种”我之前弄的东西原来是这样“的感觉。同时在这章实践和思考的部分我突然联想到了许多年前自己看到的新闻——关于Alpha Go zero的出色性能。在当时我为其不像上一代要喂棋谱而只是单纯的自我博弈和学习的训练机制而震惊，没想到多年后的今天才发现这或许就是强化学习和人工智能未来的方向。这章虽然没有将理论基础全学懂，但在强化学习上对其有了一个更清晰的认知。

### 第七章：

这章有点太”综述“了，有点看完就忘的感觉，学习完后也就是稍微了解了多模态的LLM的架构。其实关于这一章反而我作为LLM的使用者的经验要更多，我也曾为GPT更新后的图像生成能力所震惊。

### 第十一章：

主要是学了rouge和bleu这两种评估方法，对于其他的评估标准和体系也稍微有了了解。rouge是我之前就了解过的，其算式和定义我更加清楚了，而bleu我之前也经常在实践中使用，现在算是对其的原理有了理解和认知。并且我还探讨了这两者的区别和作用。实验上就是运行了简单的几行关于麦克尼马尔检验的代码。也看到了这章介绍的我之前就比较熟悉的LM Arena。



