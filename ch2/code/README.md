### 关于transformer原论文中的复现：

* 由于和鲸社区的镜像只能使用官网提供的几个，没有办法完全按照requirements中的要求复现了。最开始尝试使用python=3.8.5，torch=1.6的镜像，但其中torchtext这个包要么就是没有匹配到1.18版本要么就是2.0+了，运行时总是因为版本没能完全配置好而报错一些包里的接口不兼容的问题。
* 随后我就尝试了使用我还算比较熟悉的torch=2.5.1的框架了，将torchtext包舍弃，自己另外补全分词的部分。然后就是书本配套的代码是CPU版，稍作修改后改为了GPU版。

### 关于bert预训练：

* 尝试了一下，发现光数据集就得下两个小时，想训练10个epoch估计得等到天荒地老了，硬件设施实在是不太够





