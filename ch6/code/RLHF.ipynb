{"cells":[{"cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"16BEDEF83DF24B65ABB0E52615CECDCB","scrolled":false,"notebookId":"68bfe852e715157629b2801e"},"source":"!cp -r /home/mw/input/RLHF47374737/. /home/mw/temp","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"id":"CB65B04AB83F4EC4A5B0FF8193905260","notebookId":"68bfe852e715157629b2801e","jupyter":{},"collapsed":true,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"!cd /home/mw/temp && pip install -r requirements.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\n!pip install --upgrade transformers -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple","outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[33mDEPRECATION: Loading egg at /opt/conda/lib/python3.11/site-packages/papermill-2.3.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\nRequirement already satisfied: verl==0.3.0.post0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.3.0.post0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.10.1)\nRequirement already satisfied: codetiming in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.4.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (3.6.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.3.8)\nRequirement already satisfied: hydra-core in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.3.2)\nRequirement already satisfied: liger-kernel in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.6.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.25.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.2.2)\nRequirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.17.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (16.1.0)\nRequirement already satisfied: pybind11 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (2.13.6)\nRequirement already satisfied: pylatexenc in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (2.10)\nRequirement already satisfied: pre-commit in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (4.3.0)\nRequirement already satisfied: tensordict<=0.6.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (0.6.2)\nRequirement already satisfied: torchdata in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (0.11.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (4.56.1)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (0.21.3)\nRequirement already satisfied: megatron in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (0.5.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (3.10.6)\nRequirement already satisfied: megatron.core in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.13.1)\nRequirement already satisfied: ray[default] in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (2.24.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate->-r requirements.txt (line 2)) (24.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->-r requirements.txt (line 2)) (5.9.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate->-r requirements.txt (line 2)) (6.0.1)\nRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate->-r requirements.txt (line 2)) (2.5.1)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate->-r requirements.txt (line 2)) (0.34.4)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate->-r requirements.txt (line 2)) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 4)) (3.17.0)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 4)) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 4)) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 4)) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 4)) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (2024.5.0)\nRequirement already satisfied: omegaconf<2.4,>=2.2 in /opt/conda/lib/python3.11/site-packages (from hydra-core->-r requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from hydra-core->-r requirements.txt (line 6)) (4.9.3)\nRequirement already satisfied: triton>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from liger-kernel->-r requirements.txt (line 7)) (3.1.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 9)) (2.9.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 9)) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 9)) (2024.1)\nRequirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from pre-commit->-r requirements.txt (line 14)) (3.4.0)\nRequirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pre-commit->-r requirements.txt (line 14)) (2.6.14)\nRequirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.11/site-packages (from pre-commit->-r requirements.txt (line 14)) (1.9.1)\nRequirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.11/site-packages (from pre-commit->-r requirements.txt (line 14)) (20.29.1)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (8.1.7)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (4.21.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (1.0.8)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (5.27.1)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (1.4.1)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (3.9.5)\nRequirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (0.7.0)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (0.4.0)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (0.11.4)\nRequirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (2.10.6)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (0.20.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (7.1.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (1.70.0)\nRequirement already satisfied: memray in /opt/conda/lib/python3.11/site-packages (from ray[default]->-r requirements.txt (line 15)) (1.15.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from tensordict<=0.6.2->-r requirements.txt (line 16)) (3.0.0)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.11/site-packages (from tensordict<=0.6.2->-r requirements.txt (line 16)) (3.10.5)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.11/site-packages (from torchdata->-r requirements.txt (line 17)) (2.2.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (2024.5.15)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 18)) (0.22.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 20)) (3.1.45)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 20)) (4.2.0)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 20)) (2.37.1)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 20)) (4.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 22)) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 22)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 22)) (4.59.2)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 22)) (1.4.9)\nRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 22)) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 22)) (3.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp>=3.7->ray[default]->-r requirements.txt (line 15)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp>=3.7->ray[default]->-r requirements.txt (line 15)) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp>=3.7->ray[default]->-r requirements.txt (line 15)) (1.9.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 20)) (4.0.12)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate->-r requirements.txt (line 2)) (1.1.9)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]->-r requirements.txt (line 15)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]->-r requirements.txt (line 15)) (2.27.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 9)) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 4)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 4)) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 4)) (2024.2.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (3.1.3)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (1.3.0)\nRequirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 14)) (0.3.9)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[default]->-r requirements.txt (line 15)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[default]->-r requirements.txt (line 15)) (0.34.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[default]->-r requirements.txt (line 15)) (0.18.0)\nRequirement already satisfied: rich>=11.2.0 in /opt/conda/lib/python3.11/site-packages (from memray->ray[default]->-r requirements.txt (line 15)) (13.7.1)\nRequirement already satisfied: textual>=0.41.0 in /opt/conda/lib/python3.11/site-packages (from memray->ray[default]->-r requirements.txt (line 15)) (1.0.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from opencensus->ray[default]->-r requirements.txt (line 15)) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from opencensus->ray[default]->-r requirements.txt (line 15)) (2.24.1)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open->ray[default]->-r requirements.txt (line 15)) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 20)) (5.0.2)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (1.66.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (1.26.0)\nRequirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/conda/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (2.38.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate->-r requirements.txt (line 2)) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.2.0->memray->ray[default]->-r requirements.txt (line 15)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.2.0->memray->ray[default]->-r requirements.txt (line 15)) (2.17.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (5.5.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (4.7.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]->-r requirements.txt (line 15)) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]->-r requirements.txt (line 15)) (2.0.3)\nRequirement already satisfied: mdit-py-plugins in /opt/conda/lib/python3.11/site-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]->-r requirements.txt (line 15)) (0.4.2)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.11/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]->-r requirements.txt (line 15)) (1.0.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->-r requirements.txt (line 15)) (0.6.0)\n\u001b[33mDEPRECATION: Loading egg at /opt/conda/lib/python3.11/site-packages/papermill-2.3.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\nRequirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.56.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.34.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.25.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.0)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"}],"execution_count":2},{"cell_type":"code","metadata":{"id":"311EA19A1D7B4B20878506EC063EFE5F","notebookId":"68bfe852e715157629b2801e","jupyter":{},"collapsed":true,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"!pip install /home/mw/temp/flash_attn-2.8.3+cu12torch2.5cxx11abiFALSE-cp311-cp311-linux_x86_64.whl","outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[33mDEPRECATION: Loading egg at /opt/conda/lib/python3.11/site-packages/papermill-2.3.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n\u001b[0mProcessing /home/mw/temp/flash_attn-2.8.3+cu12torch2.5cxx11abiFALSE-cp311-cp311-linux_x86_64.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (2.5.1)\nRequirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (0.8.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (4.12.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (3.1.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (2024.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->flash-attn==2.8.3+cu12torch2.5cxx11abiFALSE) (2.1.5)\nflash-attn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"}],"execution_count":3},{"cell_type":"code","metadata":{"id":"F237F794134F47DDAF1E9BE8B054F175","notebookId":"68bfe852e715157629b2801e","jupyter":{},"collapsed":true,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"!cd /home/mw/temp && python dataset.py","outputs":[{"output_type":"stream","name":"stdout","text":"^C\r\nTraceback (most recent call last):\r\n  File \"/home/mw/temp/dataset.py\", line 46, in <module>\r\n    prepare_gsm8k(save_directory)\r\n  File \"/home/mw/temp/dataset.py\", line 11, in prepare_gsm8k\r\n    dataset = load_dataset(\"gsm8k\", \"main\")\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/datasets/load.py\", line 2062, in load_dataset\r\n    builder_instance = load_dataset_builder(\r\n                       ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/datasets/load.py\", line 1782, in load_dataset_builder\r\n    dataset_module = dataset_module_factory(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/datasets/load.py\", line 1580, in dataset_module_factory\r\n    dataset_script_path = api.hf_hub_download(\r\n                          ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/hf_api.py\", line 5528, in hf_hub_download\r\n    return hf_hub_download(\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\r\n    return _hf_hub_download_to_cache_dir(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1073, in _hf_hub_download_to_cache_dir\r\n    (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(\r\n                                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1546, in _get_metadata_or_catch_error\r\n    metadata = get_hf_file_metadata(\r\n               ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1463, in get_hf_file_metadata\r\n    r = _request_wrapper(\r\n        ^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 305, in _request_wrapper\r\n    return _request_wrapper(method=method, url=next_url, follow_relative_redirects=True, **params)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\r\n    response = _request_wrapper(\r\n               ^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 309, in _request_wrapper\r\n    response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(429,))\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py\", line 310, in http_backoff\r\n    response = session.request(method=method, url=url, **kwargs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\r\n    r = adapter.send(request, **kwargs)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py\", line 96, in send\r\n    return super().send(request, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\r\n    resp = conn.urlopen(\r\n           ^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\r\n    response = self._make_request(\r\n               ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\r\n    response = conn.getresponse()\r\n               ^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/site-packages/urllib3/connection.py\", line 466, in getresponse\r\n    httplib_response = super().getresponse()\r\n                       ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/http/client.py\", line 1390, in getresponse\r\n    response.begin()\r\n  File \"/opt/conda/lib/python3.11/http/client.py\", line 325, in begin\r\n    version, status, reason = self._read_status()\r\n                              ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/http/client.py\", line 286, in _read_status\r\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\r\n    return self._sock.recv_into(b)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/ssl.py\", line 1314, in recv_into\r\n    return self.read(nbytes, buffer)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/conda/lib/python3.11/ssl.py\", line 1166, in read\r\n    return self._sslobj.read(len, buffer)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nKeyboardInterrupt\r\n"}],"execution_count":4},{"cell_type":"code","metadata":{"id":"DBA2837D56754674AF6956DC62F9A477","notebookId":"68bfe852e715157629b2801e","jupyter":{},"collapsed":true,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"!cd /home/mw/temp/apex && pip install -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple --no-build-isolation -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./","outputs":[{"output_type":"stream","name":"stdout","text":"Using pip 24.0 from /opt/conda/lib/python3.11/site-packages/pip (python 3.11)\n\u001b[33mDEPRECATION: --build-option and --global-option are deprecated. pip 24.2 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/conda/lib/python3.11/site-packages/papermill-2.3.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\nProcessing /home/mw/temp/apex\n  Running command Preparing metadata (pyproject.toml)\n\n\n  torch.__version__  = 2.5.1+cu124\n\n\n  running dist_info\n  creating /tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info\n  writing /tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/PKG-INFO\n  writing dependency_links to /tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/dependency_links.txt\n  writing requirements to /tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/requires.txt\n  writing top-level names to /tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/top_level.txt\n  writing manifest file '/tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/SOURCES.txt'\n  reading manifest file '/tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/SOURCES.txt'\n  adding license file 'LICENSE'\n  writing manifest file '/tmp/pip-modern-metadata-u2vgpg7v/apex.egg-info/SOURCES.txt'\n  creating '/tmp/pip-modern-metadata-u2vgpg7v/apex-0.1.dist-info'\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: packaging>20.6 in /opt/conda/lib/python3.11/site-packages (from apex==0.1) (24.0)\nBuilding wheels for collected packages: apex\n\u001b[33m  WARNING: Ignoring --global-option when building apex using PEP 517\u001b[0m\u001b[33m\n\u001b[0m  Running command Building wheel for apex (pyproject.toml)\n\n\n  torch.__version__  = 2.5.1+cu124\n\n\n  running bdist_wheel\n  running build\n  running build_py\n  copying multi_tensor_apply/__init__.py -> build/lib/multi_tensor_apply\n  copying multi_tensor_apply/multi_tensor_apply.py -> build/lib/multi_tensor_apply\n  copying fused_dense/__init__.py -> build/lib/fused_dense\n  copying fused_dense/fused_dense.py -> build/lib/fused_dense\n  copying transformer/_ucc_util.py -> build/lib/transformer\n  copying transformer/enums.py -> build/lib/transformer\n  copying transformer/__init__.py -> build/lib/transformer\n  copying transformer/utils.py -> build/lib/transformer\n  copying transformer/microbatches.py -> build/lib/transformer\n  copying transformer/parallel_state.py -> build/lib/transformer\n  copying transformer/log_util.py -> build/lib/transformer\n  copying normalization/fused_layer_norm.py -> build/lib/normalization\n  copying normalization/__init__.py -> build/lib/normalization\n  copying optimizers/fused_novograd.py -> build/lib/optimizers\n  copying optimizers/fused_sgd.py -> build/lib/optimizers\n  copying optimizers/fused_adagrad.py -> build/lib/optimizers\n  copying optimizers/__init__.py -> build/lib/optimizers\n  copying optimizers/fused_mixed_precision_lamb.py -> build/lib/optimizers\n  copying optimizers/fused_lamb.py -> build/lib/optimizers\n  copying optimizers/fused_adam.py -> build/lib/optimizers\n  copying mlp/__init__.py -> build/lib/mlp\n  copying mlp/mlp.py -> build/lib/mlp\n  copying contrib/__init__.py -> build/lib/contrib\n  copying transformer/functional/__init__.py -> build/lib/transformer/functional\n  copying transformer/functional/fused_rope.py -> build/lib/transformer/functional\n  copying transformer/functional/fused_softmax.py -> build/lib/transformer/functional\n  copying transformer/amp/grad_scaler.py -> build/lib/transformer/amp\n  copying transformer/amp/__init__.py -> build/lib/transformer/amp\n  copying transformer/layers/__init__.py -> build/lib/transformer/layers\n  copying transformer/layers/layer_norm.py -> build/lib/transformer/layers\n  copying transformer/tensor_parallel/cross_entropy.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/__init__.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/memory.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/utils.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/layers.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/random.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/data.py -> build/lib/transformer/tensor_parallel\n  copying transformer/tensor_parallel/mappings.py -> build/lib/transformer/tensor_parallel\n  copying transformer/_data/_batchsampler.py -> build/lib/transformer/_data\n  copying transformer/_data/__init__.py -> build/lib/transformer/_data\n  copying transformer/testing/arguments.py -> build/lib/transformer/testing\n  copying transformer/testing/global_vars.py -> build/lib/transformer/testing\n  copying transformer/testing/distributed_test_base.py -> build/lib/transformer/testing\n  copying transformer/testing/__init__.py -> build/lib/transformer/testing\n  copying transformer/testing/standalone_bert.py -> build/lib/transformer/testing\n  copying transformer/testing/standalone_gpt.py -> build/lib/transformer/testing\n  copying transformer/testing/commons.py -> build/lib/transformer/testing\n  copying transformer/testing/standalone_transformer_lm.py -> build/lib/transformer/testing\n  copying transformer/pipeline_parallel/__init__.py -> build/lib/transformer/pipeline_parallel\n  copying transformer/pipeline_parallel/p2p_communication.py -> build/lib/transformer/pipeline_parallel\n  copying transformer/pipeline_parallel/utils.py -> build/lib/transformer/pipeline_parallel\n  copying transformer/pipeline_parallel/_timers.py -> build/lib/transformer/pipeline_parallel\n  copying transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib/transformer/pipeline_parallel/schedules\n  copying transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib/transformer/pipeline_parallel/schedules\n  copying transformer/pipeline_parallel/schedules/common.py -> build/lib/transformer/pipeline_parallel/schedules\n  copying transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib/transformer/pipeline_parallel/schedules\n  copying transformer/pipeline_parallel/schedules/__init__.py -> build/lib/transformer/pipeline_parallel/schedules\n  copying contrib/cudnn_gbn/__init__.py -> build/lib/contrib/cudnn_gbn\n  copying contrib/cudnn_gbn/batch_norm.py -> build/lib/contrib/cudnn_gbn\n  copying contrib/layer_norm/__init__.py -> build/lib/contrib/layer_norm\n  copying contrib/layer_norm/layer_norm.py -> build/lib/contrib/layer_norm\n  copying contrib/bottleneck/test.py -> build/lib/contrib/bottleneck\n  copying contrib/bottleneck/__init__.py -> build/lib/contrib/bottleneck\n  copying contrib/bottleneck/halo_exchangers.py -> build/lib/contrib/bottleneck\n  copying contrib/bottleneck/bottleneck.py -> build/lib/contrib/bottleneck\n  copying contrib/openfold_triton/mha.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/_layer_norm_config_hopper.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/fused_adam_swa.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/_layer_norm_config_ampere.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/__init__.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/_mha_kernel.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/layer_norm.py -> build/lib/contrib/openfold_triton\n  copying contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/lib/contrib/openfold_triton\n  copying contrib/sparsity/sparse_masklib.py -> build/lib/contrib/sparsity\n  copying contrib/sparsity/asp.py -> build/lib/contrib/sparsity\n  copying contrib/sparsity/__init__.py -> build/lib/contrib/sparsity\n  copying contrib/sparsity/permutation_lib.py -> build/lib/contrib/sparsity\n  copying contrib/peer_memory/__init__.py -> build/lib/contrib/peer_memory\n  copying contrib/peer_memory/peer_memory.py -> build/lib/contrib/peer_memory\n  copying contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib/contrib/peer_memory\n  copying contrib/gpu_direct_storage/__init__.py -> build/lib/contrib/gpu_direct_storage\n  copying contrib/group_norm/group_norm.py -> build/lib/contrib/group_norm\n  copying contrib/group_norm/__init__.py -> build/lib/contrib/group_norm\n  copying contrib/transducer/__init__.py -> build/lib/contrib/transducer\n  copying contrib/transducer/transducer.py -> build/lib/contrib/transducer\n  copying contrib/transducer/_transducer_ref.py -> build/lib/contrib/transducer\n  copying contrib/index_mul_2d/__init__.py -> build/lib/contrib/index_mul_2d\n  copying contrib/index_mul_2d/index_mul_2d.py -> build/lib/contrib/index_mul_2d\n  copying contrib/optimizers/fused_sgd.py -> build/lib/contrib/optimizers\n  copying contrib/optimizers/fp16_optimizer.py -> build/lib/contrib/optimizers\n  copying contrib/optimizers/__init__.py -> build/lib/contrib/optimizers\n  copying contrib/optimizers/distributed_fused_adam.py -> build/lib/contrib/optimizers\n  copying contrib/optimizers/fused_lamb.py -> build/lib/contrib/optimizers\n  copying contrib/optimizers/distributed_fused_lamb.py -> build/lib/contrib/optimizers\n  copying contrib/optimizers/fused_adam.py -> build/lib/contrib/optimizers\n  copying contrib/conv_bias_relu/__init__.py -> build/lib/contrib/conv_bias_relu\n  copying contrib/conv_bias_relu/conv_bias_relu.py -> build/lib/contrib/conv_bias_relu\n  copying contrib/fmha/__init__.py -> build/lib/contrib/fmha\n  copying contrib/fmha/fmha.py -> build/lib/contrib/fmha\n  copying contrib/clip_grad/__init__.py -> build/lib/contrib/clip_grad\n  copying contrib/clip_grad/clip_grad.py -> build/lib/contrib/clip_grad\n  copying contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/__init__.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/self_multihead_attn.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/contrib/multihead_attn\n  copying contrib/nccl_allocator/__init__.py -> build/lib/contrib/nccl_allocator\n  copying contrib/nccl_allocator/nccl_allocator.py -> build/lib/contrib/nccl_allocator\n  copying contrib/focal_loss/__init__.py -> build/lib/contrib/focal_loss\n  copying contrib/focal_loss/focal_loss.py -> build/lib/contrib/focal_loss\n  copying contrib/xentropy/__init__.py -> build/lib/contrib/xentropy\n  copying contrib/xentropy/softmax_xentropy.py -> build/lib/contrib/xentropy\n  copying contrib/torchsched/backend.py -> build/lib/contrib/torchsched\n  copying contrib/torchsched/__init__.py -> build/lib/contrib/torchsched\n  copying contrib/torchsched/config.py -> build/lib/contrib/torchsched\n  copying contrib/groupbn/__init__.py -> build/lib/contrib/groupbn\n  copying contrib/groupbn/batch_norm.py -> build/lib/contrib/groupbn\n  copying contrib/test/__init__.py -> build/lib/contrib/test\n  copying contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib/contrib/sparsity/permutation_search_kernels\n  copying contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib/contrib/sparsity/permutation_search_kernels\n  copying contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib/contrib/sparsity/permutation_search_kernels\n  copying contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib/contrib/sparsity/permutation_search_kernels\n  copying contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib/contrib/sparsity/permutation_search_kernels\n  copying contrib/torchsched/ops/__init__.py -> build/lib/contrib/torchsched/ops\n  copying contrib/torchsched/ops/layer_norm.py -> build/lib/contrib/torchsched/ops\n  copying contrib/torchsched/inductor/_utils.py -> build/lib/contrib/torchsched/inductor\n  copying contrib/torchsched/inductor/graph.py -> build/lib/contrib/torchsched/inductor\n  copying contrib/torchsched/inductor/__init__.py -> build/lib/contrib/torchsched/inductor\n  copying contrib/torchsched/inductor/scheduler.py -> build/lib/contrib/torchsched/inductor\n  copying contrib/torchsched/inductor/wrapper.py -> build/lib/contrib/torchsched/inductor\n  copying contrib/torchsched/inductor/event.py -> build/lib/contrib/torchsched/inductor\n  copying contrib/torchsched/passes/pre_grad_passes.py -> build/lib/contrib/torchsched/passes\n  copying contrib/torchsched/passes/__init__.py -> build/lib/contrib/torchsched/passes\n  copying contrib/test/cudnn_gbn/__init__.py -> build/lib/contrib/test/cudnn_gbn\n  copying contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib/contrib/test/cudnn_gbn\n  copying contrib/test/layer_norm/__init__.py -> build/lib/contrib/test/layer_norm\n  copying contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib/contrib/test/layer_norm\n  copying contrib/test/bottleneck/__init__.py -> build/lib/contrib/test/bottleneck\n  copying contrib/test/bottleneck/test_bottleneck_module.py -> build/lib/contrib/test/bottleneck\n  copying contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib/contrib/test/peer_memory\n  copying contrib/test/peer_memory/__init__.py -> build/lib/contrib/test/peer_memory\n  copying contrib/test/group_norm/__init__.py -> build/lib/contrib/test/group_norm\n  copying contrib/test/group_norm/test_group_norm.py -> build/lib/contrib/test/group_norm\n  copying contrib/test/transducer/__init__.py -> build/lib/contrib/test/transducer\n  copying contrib/test/transducer/test_transducer_joint.py -> build/lib/contrib/test/transducer\n  copying contrib/test/transducer/test_transducer_loss.py -> build/lib/contrib/test/transducer\n  copying contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib/contrib/test/index_mul_2d\n  copying contrib/test/index_mul_2d/__init__.py -> build/lib/contrib/test/index_mul_2d\n  copying contrib/test/optimizers/test_dist_adam.py -> build/lib/contrib/test/optimizers\n  copying contrib/test/optimizers/__init__.py -> build/lib/contrib/test/optimizers\n  copying contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib/contrib/test/optimizers\n  copying contrib/test/conv_bias_relu/__init__.py -> build/lib/contrib/test/conv_bias_relu\n  copying contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib/contrib/test/conv_bias_relu\n  copying contrib/test/fmha/__init__.py -> build/lib/contrib/test/fmha\n  copying contrib/test/fmha/test_fmha.py -> build/lib/contrib/test/fmha\n  copying contrib/test/clip_grad/__init__.py -> build/lib/contrib/test/clip_grad\n  copying contrib/test/clip_grad/test_clip_grad.py -> build/lib/contrib/test/clip_grad\n  copying contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/multihead_attn/__init__.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib/contrib/test/multihead_attn\n  copying contrib/test/focal_loss/__init__.py -> build/lib/contrib/test/focal_loss\n  copying contrib/test/focal_loss/test_focal_loss.py -> build/lib/contrib/test/focal_loss\n  copying contrib/test/xentropy/__init__.py -> build/lib/contrib/test/xentropy\n  copying contrib/test/xentropy/test_label_smoothing.py -> build/lib/contrib/test/xentropy\n  installing to build/bdist.linux-x86_64/wheel\n  running install\n  running install_lib\n  creating build/bdist.linux-x86_64/wheel\n  creating build/bdist.linux-x86_64/wheel/multi_tensor_apply\n  copying build/lib/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/multi_tensor_apply\n  copying build/lib/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/multi_tensor_apply\n  creating build/bdist.linux-x86_64/wheel/fused_dense\n  copying build/lib/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/fused_dense\n  copying build/lib/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/fused_dense\n  creating build/bdist.linux-x86_64/wheel/transformer\n  copying build/lib/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/transformer\n  creating build/bdist.linux-x86_64/wheel/transformer/functional\n  copying build/lib/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/functional\n  copying build/lib/transformer/functional/fused_rope.py -> build/bdist.linux-x86_64/wheel/transformer/functional\n  copying build/lib/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/transformer/functional\n  copying build/lib/transformer/enums.py -> build/bdist.linux-x86_64/wheel/transformer\n  copying build/lib/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/transformer\n  creating build/bdist.linux-x86_64/wheel/transformer/amp\n  copying build/lib/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/transformer/amp\n  copying build/lib/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/amp\n  creating build/bdist.linux-x86_64/wheel/transformer/layers\n  copying build/lib/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/layers\n  copying build/lib/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/transformer/layers\n  copying build/lib/transformer/utils.py -> build/bdist.linux-x86_64/wheel/transformer\n  copying build/lib/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/transformer\n  creating build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  copying build/lib/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/transformer/tensor_parallel\n  creating build/bdist.linux-x86_64/wheel/transformer/_data\n  copying build/lib/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/transformer/_data\n  copying build/lib/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/_data\n  copying build/lib/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/transformer\n  copying build/lib/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/transformer\n  creating build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  copying build/lib/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/transformer/testing\n  creating build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel\n  copying build/lib/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel\n  creating build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel/schedules\n  copying build/lib/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel/schedules\n  copying build/lib/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel/schedules\n  copying build/lib/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel/schedules\n  copying build/lib/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel/schedules\n  copying build/lib/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel/schedules\n  copying build/lib/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel\n  copying build/lib/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel\n  copying build/lib/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/transformer/pipeline_parallel\n  creating build/bdist.linux-x86_64/wheel/normalization\n  copying build/lib/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/normalization\n  copying build/lib/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/normalization\n  creating build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/optimizers\n  copying build/lib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/optimizers\n  creating build/bdist.linux-x86_64/wheel/mlp\n  copying build/lib/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/mlp\n  copying build/lib/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/mlp\n  creating build/bdist.linux-x86_64/wheel/contrib\n  creating build/bdist.linux-x86_64/wheel/contrib/cudnn_gbn\n  copying build/lib/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/cudnn_gbn\n  copying build/lib/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/contrib/cudnn_gbn\n  creating build/bdist.linux-x86_64/wheel/contrib/layer_norm\n  copying build/lib/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/layer_norm\n  copying build/lib/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/contrib/layer_norm\n  creating build/bdist.linux-x86_64/wheel/contrib/bottleneck\n  copying build/lib/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/contrib/bottleneck\n  copying build/lib/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/bottleneck\n  copying build/lib/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/contrib/bottleneck\n  copying build/lib/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/contrib/bottleneck\n  creating build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/mha.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/fused_adam_swa.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/_mha_kernel.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  copying build/lib/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/bdist.linux-x86_64/wheel/contrib/openfold_triton\n  creating build/bdist.linux-x86_64/wheel/contrib/sparsity\n  copying build/lib/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity\n  copying build/lib/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity\n  copying build/lib/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity\n  copying build/lib/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity\n  creating build/bdist.linux-x86_64/wheel/contrib/sparsity/permutation_search_kernels\n  copying build/lib/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity/permutation_search_kernels\n  copying build/lib/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity/permutation_search_kernels\n  copying build/lib/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity/permutation_search_kernels\n  copying build/lib/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity/permutation_search_kernels\n  copying build/lib/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/contrib/sparsity/permutation_search_kernels\n  creating build/bdist.linux-x86_64/wheel/contrib/peer_memory\n  copying build/lib/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/peer_memory\n  copying build/lib/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/contrib/peer_memory\n  copying build/lib/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/contrib/peer_memory\n  copying build/lib/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/contrib\n  creating build/bdist.linux-x86_64/wheel/contrib/gpu_direct_storage\n  copying build/lib/contrib/gpu_direct_storage/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/gpu_direct_storage\n  creating build/bdist.linux-x86_64/wheel/contrib/group_norm\n  copying build/lib/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/wheel/contrib/group_norm\n  copying build/lib/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/group_norm\n  creating build/bdist.linux-x86_64/wheel/contrib/transducer\n  copying build/lib/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/transducer\n  copying build/lib/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/contrib/transducer\n  copying build/lib/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/contrib/transducer\n  creating build/bdist.linux-x86_64/wheel/contrib/index_mul_2d\n  copying build/lib/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/index_mul_2d\n  copying build/lib/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/contrib/index_mul_2d\n  creating build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  copying build/lib/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/contrib/optimizers\n  creating build/bdist.linux-x86_64/wheel/contrib/conv_bias_relu\n  copying build/lib/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/conv_bias_relu\n  copying build/lib/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/contrib/conv_bias_relu\n  creating build/bdist.linux-x86_64/wheel/contrib/fmha\n  copying build/lib/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/fmha\n  copying build/lib/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/contrib/fmha\n  creating build/bdist.linux-x86_64/wheel/contrib/clip_grad\n  copying build/lib/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/clip_grad\n  copying build/lib/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/contrib/clip_grad\n  creating build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  copying build/lib/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/contrib/multihead_attn\n  creating build/bdist.linux-x86_64/wheel/contrib/nccl_allocator\n  copying build/lib/contrib/nccl_allocator/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/nccl_allocator\n  copying build/lib/contrib/nccl_allocator/nccl_allocator.py -> build/bdist.linux-x86_64/wheel/contrib/nccl_allocator\n  creating build/bdist.linux-x86_64/wheel/contrib/focal_loss\n  copying build/lib/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/focal_loss\n  copying build/lib/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/contrib/focal_loss\n  creating build/bdist.linux-x86_64/wheel/contrib/xentropy\n  copying build/lib/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/xentropy\n  copying build/lib/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/contrib/xentropy\n  creating build/bdist.linux-x86_64/wheel/contrib/torchsched\n  creating build/bdist.linux-x86_64/wheel/contrib/torchsched/ops\n  copying build/lib/contrib/torchsched/ops/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/ops\n  copying build/lib/contrib/torchsched/ops/layer_norm.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/ops\n  copying build/lib/contrib/torchsched/backend.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched\n  copying build/lib/contrib/torchsched/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched\n  creating build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  copying build/lib/contrib/torchsched/inductor/_utils.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  copying build/lib/contrib/torchsched/inductor/graph.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  copying build/lib/contrib/torchsched/inductor/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  copying build/lib/contrib/torchsched/inductor/scheduler.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  copying build/lib/contrib/torchsched/inductor/wrapper.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  copying build/lib/contrib/torchsched/inductor/event.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/inductor\n  creating build/bdist.linux-x86_64/wheel/contrib/torchsched/passes\n  copying build/lib/contrib/torchsched/passes/pre_grad_passes.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/passes\n  copying build/lib/contrib/torchsched/passes/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched/passes\n  copying build/lib/contrib/torchsched/config.py -> build/bdist.linux-x86_64/wheel/contrib/torchsched\n  creating build/bdist.linux-x86_64/wheel/contrib/groupbn\n  copying build/lib/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/groupbn\n  copying build/lib/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/contrib/groupbn\n  creating build/bdist.linux-x86_64/wheel/contrib/test\n  creating build/bdist.linux-x86_64/wheel/contrib/test/cudnn_gbn\n  copying build/lib/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/cudnn_gbn\n  copying build/lib/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/contrib/test/cudnn_gbn\n  creating build/bdist.linux-x86_64/wheel/contrib/test/layer_norm\n  copying build/lib/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/layer_norm\n  copying build/lib/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/contrib/test/layer_norm\n  creating build/bdist.linux-x86_64/wheel/contrib/test/bottleneck\n  copying build/lib/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/bottleneck\n  copying build/lib/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/contrib/test/bottleneck\n  creating build/bdist.linux-x86_64/wheel/contrib/test/peer_memory\n  copying build/lib/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/contrib/test/peer_memory\n  copying build/lib/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/peer_memory\n  copying build/lib/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test\n  creating build/bdist.linux-x86_64/wheel/contrib/test/group_norm\n  copying build/lib/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/group_norm\n  copying build/lib/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/wheel/contrib/test/group_norm\n  creating build/bdist.linux-x86_64/wheel/contrib/test/transducer\n  copying build/lib/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/transducer\n  copying build/lib/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/contrib/test/transducer\n  copying build/lib/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/contrib/test/transducer\n  creating build/bdist.linux-x86_64/wheel/contrib/test/index_mul_2d\n  copying build/lib/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/contrib/test/index_mul_2d\n  copying build/lib/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/index_mul_2d\n  creating build/bdist.linux-x86_64/wheel/contrib/test/optimizers\n  copying build/lib/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/contrib/test/optimizers\n  copying build/lib/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/optimizers\n  copying build/lib/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/contrib/test/optimizers\n  creating build/bdist.linux-x86_64/wheel/contrib/test/conv_bias_relu\n  copying build/lib/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/conv_bias_relu\n  copying build/lib/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/contrib/test/conv_bias_relu\n  creating build/bdist.linux-x86_64/wheel/contrib/test/fmha\n  copying build/lib/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/fmha\n  copying build/lib/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/contrib/test/fmha\n  creating build/bdist.linux-x86_64/wheel/contrib/test/clip_grad\n  copying build/lib/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/clip_grad\n  copying build/lib/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/contrib/test/clip_grad\n  creating build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  copying build/lib/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/contrib/test/multihead_attn\n  creating build/bdist.linux-x86_64/wheel/contrib/test/focal_loss\n  copying build/lib/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/focal_loss\n  copying build/lib/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/contrib/test/focal_loss\n  creating build/bdist.linux-x86_64/wheel/contrib/test/xentropy\n  copying build/lib/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/contrib/test/xentropy\n  copying build/lib/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/contrib/test/xentropy\n  running install_egg_info\n  running egg_info\n  writing apex.egg-info/PKG-INFO\n  writing dependency_links to apex.egg-info/dependency_links.txt\n  writing requirements to apex.egg-info/requires.txt\n  writing top-level names to apex.egg-info/top_level.txt\n  reading manifest file 'apex.egg-info/SOURCES.txt'\n  adding license file 'LICENSE'\n  writing manifest file 'apex.egg-info/SOURCES.txt'\n  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.11.egg-info\n  running install_scripts\n  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n  creating '/tmp/pip-wheel-e1cx8d2l/.tmp-irpfcidl/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n  adding 'contrib/__init__.py'\n  adding 'contrib/bottleneck/__init__.py'\n  adding 'contrib/bottleneck/bottleneck.py'\n  adding 'contrib/bottleneck/halo_exchangers.py'\n  adding 'contrib/bottleneck/test.py'\n  adding 'contrib/clip_grad/__init__.py'\n  adding 'contrib/clip_grad/clip_grad.py'\n  adding 'contrib/conv_bias_relu/__init__.py'\n  adding 'contrib/conv_bias_relu/conv_bias_relu.py'\n  adding 'contrib/cudnn_gbn/__init__.py'\n  adding 'contrib/cudnn_gbn/batch_norm.py'\n  adding 'contrib/fmha/__init__.py'\n  adding 'contrib/fmha/fmha.py'\n  adding 'contrib/focal_loss/__init__.py'\n  adding 'contrib/focal_loss/focal_loss.py'\n  adding 'contrib/gpu_direct_storage/__init__.py'\n  adding 'contrib/group_norm/__init__.py'\n  adding 'contrib/group_norm/group_norm.py'\n  adding 'contrib/groupbn/__init__.py'\n  adding 'contrib/groupbn/batch_norm.py'\n  adding 'contrib/index_mul_2d/__init__.py'\n  adding 'contrib/index_mul_2d/index_mul_2d.py'\n  adding 'contrib/layer_norm/__init__.py'\n  adding 'contrib/layer_norm/layer_norm.py'\n  adding 'contrib/multihead_attn/__init__.py'\n  adding 'contrib/multihead_attn/encdec_multihead_attn.py'\n  adding 'contrib/multihead_attn/encdec_multihead_attn_func.py'\n  adding 'contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n  adding 'contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n  adding 'contrib/multihead_attn/fast_self_multihead_attn_func.py'\n  adding 'contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n  adding 'contrib/multihead_attn/mask_softmax_dropout_func.py'\n  adding 'contrib/multihead_attn/self_multihead_attn.py'\n  adding 'contrib/multihead_attn/self_multihead_attn_func.py'\n  adding 'contrib/nccl_allocator/__init__.py'\n  adding 'contrib/nccl_allocator/nccl_allocator.py'\n  adding 'contrib/openfold_triton/__init__.py'\n  adding 'contrib/openfold_triton/_layer_norm_backward_kernels.py'\n  adding 'contrib/openfold_triton/_layer_norm_config_ampere.py'\n  adding 'contrib/openfold_triton/_layer_norm_config_hopper.py'\n  adding 'contrib/openfold_triton/_layer_norm_forward_kernels.py'\n  adding 'contrib/openfold_triton/_mha_kernel.py'\n  adding 'contrib/openfold_triton/fused_adam_swa.py'\n  adding 'contrib/openfold_triton/layer_norm.py'\n  adding 'contrib/openfold_triton/mha.py'\n  adding 'contrib/optimizers/__init__.py'\n  adding 'contrib/optimizers/distributed_fused_adam.py'\n  adding 'contrib/optimizers/distributed_fused_lamb.py'\n  adding 'contrib/optimizers/fp16_optimizer.py'\n  adding 'contrib/optimizers/fused_adam.py'\n  adding 'contrib/optimizers/fused_lamb.py'\n  adding 'contrib/optimizers/fused_sgd.py'\n  adding 'contrib/peer_memory/__init__.py'\n  adding 'contrib/peer_memory/peer_halo_exchanger_1d.py'\n  adding 'contrib/peer_memory/peer_memory.py'\n  adding 'contrib/sparsity/__init__.py'\n  adding 'contrib/sparsity/asp.py'\n  adding 'contrib/sparsity/permutation_lib.py'\n  adding 'contrib/sparsity/sparse_masklib.py'\n  adding 'contrib/sparsity/permutation_search_kernels/__init__.py'\n  adding 'contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n  adding 'contrib/sparsity/permutation_search_kernels/channel_swap.py'\n  adding 'contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n  adding 'contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n  adding 'contrib/test/__init__.py'\n  adding 'contrib/test/bottleneck/__init__.py'\n  adding 'contrib/test/bottleneck/test_bottleneck_module.py'\n  adding 'contrib/test/clip_grad/__init__.py'\n  adding 'contrib/test/clip_grad/test_clip_grad.py'\n  adding 'contrib/test/conv_bias_relu/__init__.py'\n  adding 'contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n  adding 'contrib/test/cudnn_gbn/__init__.py'\n  adding 'contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n  adding 'contrib/test/fmha/__init__.py'\n  adding 'contrib/test/fmha/test_fmha.py'\n  adding 'contrib/test/focal_loss/__init__.py'\n  adding 'contrib/test/focal_loss/test_focal_loss.py'\n  adding 'contrib/test/group_norm/__init__.py'\n  adding 'contrib/test/group_norm/test_group_norm.py'\n  adding 'contrib/test/index_mul_2d/__init__.py'\n  adding 'contrib/test/index_mul_2d/test_index_mul_2d.py'\n  adding 'contrib/test/layer_norm/__init__.py'\n  adding 'contrib/test/layer_norm/test_fast_layer_norm.py'\n  adding 'contrib/test/multihead_attn/__init__.py'\n  adding 'contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n  adding 'contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n  adding 'contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n  adding 'contrib/test/multihead_attn/test_mha_fused_softmax.py'\n  adding 'contrib/test/multihead_attn/test_self_multihead_attn.py'\n  adding 'contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n  adding 'contrib/test/optimizers/__init__.py'\n  adding 'contrib/test/optimizers/test_dist_adam.py'\n  adding 'contrib/test/optimizers/test_distributed_fused_lamb.py'\n  adding 'contrib/test/peer_memory/__init__.py'\n  adding 'contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n  adding 'contrib/test/transducer/__init__.py'\n  adding 'contrib/test/transducer/test_transducer_joint.py'\n  adding 'contrib/test/transducer/test_transducer_loss.py'\n  adding 'contrib/test/xentropy/__init__.py'\n  adding 'contrib/test/xentropy/test_label_smoothing.py'\n  adding 'contrib/torchsched/__init__.py'\n  adding 'contrib/torchsched/backend.py'\n  adding 'contrib/torchsched/config.py'\n  adding 'contrib/torchsched/inductor/__init__.py'\n  adding 'contrib/torchsched/inductor/_utils.py'\n  adding 'contrib/torchsched/inductor/event.py'\n  adding 'contrib/torchsched/inductor/graph.py'\n  adding 'contrib/torchsched/inductor/scheduler.py'\n  adding 'contrib/torchsched/inductor/wrapper.py'\n  adding 'contrib/torchsched/ops/__init__.py'\n  adding 'contrib/torchsched/ops/layer_norm.py'\n  adding 'contrib/torchsched/passes/__init__.py'\n  adding 'contrib/torchsched/passes/pre_grad_passes.py'\n  adding 'contrib/transducer/__init__.py'\n  adding 'contrib/transducer/_transducer_ref.py'\n  adding 'contrib/transducer/transducer.py'\n  adding 'contrib/xentropy/__init__.py'\n  adding 'contrib/xentropy/softmax_xentropy.py'\n  adding 'fused_dense/__init__.py'\n  adding 'fused_dense/fused_dense.py'\n  adding 'mlp/__init__.py'\n  adding 'mlp/mlp.py'\n  adding 'multi_tensor_apply/__init__.py'\n  adding 'multi_tensor_apply/multi_tensor_apply.py'\n  adding 'normalization/__init__.py'\n  adding 'normalization/fused_layer_norm.py'\n  adding 'optimizers/__init__.py'\n  adding 'optimizers/fused_adagrad.py'\n  adding 'optimizers/fused_adam.py'\n  adding 'optimizers/fused_lamb.py'\n  adding 'optimizers/fused_mixed_precision_lamb.py'\n  adding 'optimizers/fused_novograd.py'\n  adding 'optimizers/fused_sgd.py'\n  adding 'transformer/__init__.py'\n  adding 'transformer/_ucc_util.py'\n  adding 'transformer/enums.py'\n  adding 'transformer/log_util.py'\n  adding 'transformer/microbatches.py'\n  adding 'transformer/parallel_state.py'\n  adding 'transformer/utils.py'\n  adding 'transformer/_data/__init__.py'\n  adding 'transformer/_data/_batchsampler.py'\n  adding 'transformer/amp/__init__.py'\n  adding 'transformer/amp/grad_scaler.py'\n  adding 'transformer/functional/__init__.py'\n  adding 'transformer/functional/fused_rope.py'\n  adding 'transformer/functional/fused_softmax.py'\n  adding 'transformer/layers/__init__.py'\n  adding 'transformer/layers/layer_norm.py'\n  adding 'transformer/pipeline_parallel/__init__.py'\n  adding 'transformer/pipeline_parallel/_timers.py'\n  adding 'transformer/pipeline_parallel/p2p_communication.py'\n  adding 'transformer/pipeline_parallel/utils.py'\n  adding 'transformer/pipeline_parallel/schedules/__init__.py'\n  adding 'transformer/pipeline_parallel/schedules/common.py'\n  adding 'transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n  adding 'transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n  adding 'transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n  adding 'transformer/tensor_parallel/__init__.py'\n  adding 'transformer/tensor_parallel/cross_entropy.py'\n  adding 'transformer/tensor_parallel/data.py'\n  adding 'transformer/tensor_parallel/layers.py'\n  adding 'transformer/tensor_parallel/mappings.py'\n  adding 'transformer/tensor_parallel/memory.py'\n  adding 'transformer/tensor_parallel/random.py'\n  adding 'transformer/tensor_parallel/utils.py'\n  adding 'transformer/testing/__init__.py'\n  adding 'transformer/testing/arguments.py'\n  adding 'transformer/testing/commons.py'\n  adding 'transformer/testing/distributed_test_base.py'\n  adding 'transformer/testing/global_vars.py'\n  adding 'transformer/testing/standalone_bert.py'\n  adding 'transformer/testing/standalone_gpt.py'\n  adding 'transformer/testing/standalone_transformer_lm.py'\n  adding 'apex-0.1.dist-info/LICENSE'\n  adding 'apex-0.1.dist-info/METADATA'\n  adding 'apex-0.1.dist-info/WHEEL'\n  adding 'apex-0.1.dist-info/top_level.txt'\n  adding 'apex-0.1.dist-info/RECORD'\n  removing build/bdist.linux-x86_64/wheel\n  Building wheel for apex (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=363878 sha256=a211f1e2b349fbc693d46dc817761f840baca463830a2cf68e99b9edd04dc0e9\n  Stored in directory: /tmp/pip-ephem-wheel-cache-y4iuc17m/wheels/28/d8/fe/7305ec0636da466b49b6b6bd179583a11327ec7e70fea2c371\nSuccessfully built apex\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m"}],"execution_count":5},{"cell_type":"code","metadata":{"id":"E39D660B18BD44A0BD06FE5C07F2988B","notebookId":"68bfe852e715157629b2801e","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"!cd /home/mw/temp && bash verl_train_script.sh","outputs":[{"output_type":"stream","name":"stdout","text":"2025-09-10 04:36:20,265\tINFO worker.py:1744 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n\u001b[36m(pid=5545)\u001b[0m [HAMI-core ERROR (pid:5545 thread=140436000635776 libvgpu.c:873)]: cuInit failed:100\n\u001b[36m(TaskRunner pid=5545)\u001b[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'contents': ['model',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                              'hf_model',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                              'optimizer',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                              'extra']},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'clip_ratio': 0.2,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'entropy_coeff': 0.001,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'kl_loss_coef': 0.001,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'kl_loss_type': 'low_var_kl',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'load_weight': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'megatron': {'pipeline_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                               'seed': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                               'sequence_parallel': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                               'tensor_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                               'use_distributed_optimizer': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                               'virtual_pipeline_model_parallel_size': None},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'optim': {'clip_grad': 1.0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                            'lr': 1e-06,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                            'lr_warmup_steps': -1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                            'lr_warmup_steps_ratio': 0.0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                            'min_lr_ratio': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                            'total_training_steps': -1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                            'warmup_style': 'constant'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'ppo_epochs': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'ppo_micro_batch_size': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'ppo_micro_batch_size_per_gpu': 4,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'ppo_mini_batch_size': 32,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'shuffle': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'strategy': 'megatron',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'use_dynamic_bsz': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'use_kl_loss': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'use_torch_compile': True},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                        'hybrid_engine': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                        'model': {'enable_gradient_checkpointing': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'external_lib': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'override_config': {},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                  'path': 'Qwen/Qwen2-7B-Instruct'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                        'ref': {'load_weight': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'log_prob_micro_batch_size': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'log_prob_micro_batch_size_per_gpu': 4,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'megatron': {'pipeline_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                             'seed': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                             'sequence_parallel': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                             'tensor_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                             'use_distributed_optimizer': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                             'virtual_pipeline_model_parallel_size': None},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'param_offload': False},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                        'rollout': {'disable_log_stats': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'do_sample': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'dtype': 'bfloat16',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'enable_chunked_prefill': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'enforce_eager': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'free_cache_engine': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'gpu_memory_utilization': 0.8,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'ignore_eos': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'layer_name_map': {'gate_proj_layer_name': 'gate_up',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                       'qkv_layer_name': 'qkv'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'load_format': 'dummy_megatron',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'log_prob_micro_batch_size': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'log_prob_micro_batch_size_per_gpu': 4,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'max_model_len': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'max_num_batched_tokens': 8192,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'max_num_seqs': 1024,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'n': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'name': 'vllm',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'prompt_length': 1024,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'response_length': 512,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'temperature': 1.0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'tensor_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'top_k': -1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'top_p': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                    'val_kwargs': {'do_sample': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                   'n': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                   'temperature': 0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                   'top_k': -1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                                   'top_p': 1.0}}},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m  'algorithm': {'adv_estimator': 'gae',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                'gamma': 1.0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                'kl_penalty': 'kl',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                'lam': 1.0},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m  'critic': {'checkpoint': {'contents': ['model',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                         'hf_model',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                         'optimizer',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                         'extra']},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'cliprange_value': 0.5,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'load_weight': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'megatron': {'pipeline_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                          'seed': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                          'sequence_parallel': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                          'tensor_model_parallel_size': 4,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                          'use_distributed_optimizer': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                          'virtual_pipeline_model_parallel_size': None},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'model': {'enable_gradient_checkpointing': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'external_lib': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'override_config': {},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'path': 'Qwen/Qwen2-7B-Instruct',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'tokenizer_path': 'Qwen/Qwen2-7B-Instruct'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'optim': {'clip_grad': 1.0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'lr': 1e-05,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'lr_warmup_steps_ratio': 0.0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'min_lr_ratio': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'total_training_steps': -1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                       'warmup_style': 'constant'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'ppo_epochs': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'ppo_micro_batch_size': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'ppo_micro_batch_size_per_gpu': 4,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'ppo_mini_batch_size': 32,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'shuffle': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'strategy': 'megatron',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m             'use_dynamic_bsz': False},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m  'data': {'filter_overlong_prompts': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'max_prompt_length': 1024,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'max_response_length': 512,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'prompt_key': 'messages',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'return_raw_chat': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'return_raw_input_ids': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'shuffle': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'tokenizer': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'train_batch_size': 128,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'train_files': ['./data/gsm8k/train.parquet'],\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'truncation': 'error',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'val_batch_size': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m           'val_files': ['./data/gsm8k/test.parquet']},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m  'reward_model': {'enable': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'load_weight': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'max_length': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'megatron': {'pipeline_model_parallel_size': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'seed': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'sequence_parallel': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'tensor_model_parallel_size': 4,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'use_distributed_optimizer': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                                'virtual_pipeline_model_parallel_size': None},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'micro_batch_size': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'micro_batch_size_per_gpu': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'model': {'external_lib': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                             'input_tokenizer': 'Qwen/Qwen2-7B-Instruct',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1'},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'param_offload': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'strategy': 'megatron',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m                   'use_dynamic_bsz': False},\n\u001b[36m(TaskRunner pid=5545)\u001b[0m  'trainer': {'balance_batch': True,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'critic_warmup': 0,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'default_hdfs_dir': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'default_local_dir': 'checkpoints/verl_ppo_gsm8k_math_examples/qwen2_7b_single_gpu',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'del_local_ckpt_after_load': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'experiment_name': 'qwen2_7b_single_gpu',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'logger': ['console', 'wandb'],\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'max_actor_ckpt_to_keep': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'max_critic_ckpt_to_keep': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'n_gpus_per_node': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'nnodes': 1,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'project_name': 'verl_ppo_gsm8k_math_examples',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'resume_from_path': False,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'resume_mode': 'auto',\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'save_freq': 20,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'test_freq': 5,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'total_epochs': 100,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'total_training_steps': None,\n\u001b[36m(TaskRunner pid=5545)\u001b[0m              'val_generations_to_log_to_wandb': 0}}\n\u001b[36m(TaskRunner pid=5545)\u001b[0m /opt/conda/lib/python3.11/site-packages/megatron/core/optimizer/optimizer.py:28: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier and multi_tensor_scale\n\u001b[36m(TaskRunner pid=5545)\u001b[0m   warnings.warn(\n\u001b[36m(TaskRunner pid=5545)\u001b[0m /opt/conda/lib/python3.11/site-packages/megatron/core/optimizer/clip_grads.py:29: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier, multi_tensor_l2norm, and multi_tensor_scale\n\u001b[36m(TaskRunner pid=5545)\u001b[0m   warnings.warn(\n\u001b[36m(TaskRunner pid=5545)\u001b[0m [validate_config] All configuration checks passed successfully!\n\u001b[36m(TaskRunner pid=5545)\u001b[0m dataset len: 7473\n\u001b[36m(TaskRunner pid=5545)\u001b[0m [HAMI-core ERROR (pid:5704 thread=139923029527424 libvgpu.c:873)]: cuInit failed:100\n\u001b[36m(TaskRunner pid=5545)\u001b[0m filter dataset len: 7473\n\u001b[36m(TaskRunner pid=5545)\u001b[0m dataset len: 1319\n\u001b[36m(TaskRunner pid=5545)\u001b[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.\n\u001b[36m(TaskRunner pid=5545)\u001b[0m filter dataset len: 1319\n\u001b[36m(TaskRunner pid=5545)\u001b[0m Size of train dataloader: 58\n\u001b[36m(TaskRunner pid=5545)\u001b[0m Total training steps: 5800\n\u001b[36m(pid=5852)\u001b[0m /opt/conda/lib/python3.11/site-packages/megatron/core/optimizer/optimizer.py:28: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier and multi_tensor_scale\n\u001b[36m(pid=5852)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n\u001b[36m(pid=5852)\u001b[0m /opt/conda/lib/python3.11/site-packages/megatron/core/optimizer/clip_grads.py:29: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier, multi_tensor_l2norm, and multi_tensor_scale\nError executing job with overrides: ['algorithm.adv_estimator=gae', 'data.train_files=[./data/gsm8k/train.parquet]', 'data.val_files=[./data/gsm8k/test.parquet]', 'data.train_batch_size=128', 'data.max_prompt_length=1024', 'data.max_response_length=512', 'data.filter_overlong_prompts=True', 'data.truncation=error', 'data.prompt_key=messages', 'actor_rollout_ref.model.path=Qwen/Qwen2-7B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.ppo_mini_batch_size=32', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4', 'actor_rollout_ref.actor.megatron.pipeline_model_parallel_size=1', 'actor_rollout_ref.actor.megatron.tensor_model_parallel_size=1', 'actor_rollout_ref.actor.megatron.sequence_parallel=False', 'actor_rollout_ref.actor.use_kl_loss=False', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.8', 'actor_rollout_ref.ref.megatron.pipeline_model_parallel_size=1', 'actor_rollout_ref.ref.megatron.tensor_model_parallel_size=1', 'actor_rollout_ref.ref.megatron.sequence_parallel=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2-7B-Instruct', 'critic.megatron.sequence_parallel=False', 'critic.model.enable_gradient_checkpointing=False', 'critic.ppo_micro_batch_size_per_gpu=4', 'trainer.critic_warmup=0', 'trainer.logger=[console,wandb]', 'trainer.project_name=verl_ppo_gsm8k_math_examples', 'trainer.experiment_name=qwen2_7b_single_gpu', 'trainer.n_gpus_per_node=1', 'trainer.nnodes=1', 'trainer.save_freq=20', 'trainer.test_freq=5', 'trainer.total_epochs=100']\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/verl/trainer/main_ppo.py\", line 54, in main\n    run_ppo(config)\n  File \"/opt/conda/lib/python3.11/site-packages/verl/trainer/main_ppo.py\", line 72, in run_ppo\n    ray.get(runner.run.remote(config))\n  File \"/opt/conda/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ray/_private/worker.py\", line 2613, in get\n    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): \u001b[36mray::TaskRunner.run()\u001b[39m (pid=5545, ip=172.16.224.239, actor_id=27321103b571ea114d0b165b01000000, repr=<main_ppo.TaskRunner object at 0x7fb9c9f1bc10>)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/trainer/main_ppo.py\", line 170, in run\n    trainer.init_workers()\n  File \"/opt/conda/lib/python3.11/site-packages/verl/trainer/ppo/ray_trainer.py\", line 628, in init_workers\n    self.critic_wg.init_model()\n  File \"/opt/conda/lib/python3.11/site-packages/verl/single_controller/ray/base.py\", line 42, in func\n    output = ray.get(output)\n             ^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^^^\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nray.exceptions.RayTaskError(ValueError): \u001b[36mray::WorkerDict.critic_init_model()\u001b[39m (pid=5852, ip=172.16.224.239, actor_id=f897be1915ac7b0e9d8b1ea401000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f9f55c07b50>)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/single_controller/ray/base.py\", line 419, in func\n    return getattr(self.worker_dict[key], name)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/single_controller/base/decorator.py\", line 404, in inner\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/workers/megatron_workers.py\", line 609, in init_model\n    self.critic_module, self.critic_optimizer, self.critic_model_config, critic_optimizer_config = self._build_critic_model_optimizer(\n                                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/workers/megatron_workers.py\", line 562, in _build_critic_model_optimizer\n    critic_module = get_model(model_provider_func=megatron_critic_model_provider,\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/utils/megatron_utils.py\", line 81, in get_model\n    model = model_provider_func(pre_process=pre_process, post_process=post_process)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/workers/megatron_workers.py\", line 552, in megatron_critic_model_provider\n    parallel_model = get_parallel_model_from_config(config=critic_model_config,\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/utils/model.py\", line 261, in get_parallel_model_from_config\n    model = model_class(config,\n            ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/models/qwen2/megatron/modeling_qwen2_megatron.py\", line 524, in __init__\n    self.config: TransformerConfig = convert_config(config, megatron_config)\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/verl/utils/megatron_utils.py\", line 163, in convert_config\n    transformer_config = TransformerConfig(\n                         ^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 190, in __init__\n  File \"/opt/conda/lib/python3.11/site-packages/megatron/core/transformer/transformer_config.py\", line 636, in __post_init__\n    super().__post_init__()\n  File \"/opt/conda/lib/python3.11/site-packages/megatron/core/model_parallel_config.py\", line 356, in __post_init__\n    raise ValueError(\"Can not use sequence paralllelism without tensor parallelism\")\nValueError: Can not use sequence paralllelism without tensor parallelism\n\nSet the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n\u001b[0m\u001b[36m(WorkerDict pid=5852)\u001b[0m Model config after override: critic_model_config Qwen2Config {\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"architectures\": [\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"Qwen2ForCausalLM\"\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   ],\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"attention_dropout\": 0.0,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"dtype\": \"bfloat16\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"eos_token_id\": 151645,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"hidden_act\": \"silu\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"hidden_size\": 3584,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"initializer_range\": 0.02,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"intermediate_size\": 18944,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"layer_types\": [\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m     \"full_attention\"\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   ],\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"max_position_embeddings\": 32768,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"max_window_layers\": 28,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"model_type\": \"qwen2\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"num_attention_heads\": 28,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"num_hidden_layers\": 28,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"num_key_value_heads\": 4,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"pad_token_id\": 151643,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"rms_norm_eps\": 1e-06,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"rope_scaling\": null,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"rope_theta\": 1000000.0,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"sliding_window\": null,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"tie_word_embeddings\": false,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"transformers_version\": \"4.56.1\",\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"use_cache\": true,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"use_sliding_window\": false,\n\u001b[36m(WorkerDict pid=5852)\u001b[0m   \"vocab_size\": 152064\n\u001b[36m(WorkerDict pid=5852)\u001b[0m }\n\u001b[36m(WorkerDict pid=5852)\u001b[0m \n\u001b[36m(WorkerDict pid=5852)\u001b[0m after load model cls\n\u001b[36m(WorkerDict pid=5852)\u001b[0m megatron config ModelParallelConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=False, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=False, overlap_p2p_comm=False, batch_p2p_comm=True, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=False, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, delay_wgrad_compute=False, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True)\n\u001b[36m(WorkerDict pid=5852)\u001b[0m pipeline_dtype=megatron_config torch.bfloat16\n"}],"execution_count":2}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}