## ResNet

### 思考：

* 何恺明的天才之处在于将残差运用到了多层的卷积之中，既然新加的层数要学的是与前面层数的差异。那么后面的层的输出就可以简单得在数学层面上做一个加法。而且如果层数增加地特别多，超过了某个任务上可能的最适合的值，也会因为残差连接而使得后面的层数不会学到太多东西，从而避免对前面层次的干扰。
* 这个像导线一样的残差连接是如此的简单但却如此的有效，让底层的参数也可以被这个用于“短路”的残差连接训练到，而不是随着层数增加总是导致梯度爆炸或是梯度消失，从而可以让网络的层次变得更深，学习到更加复杂和抽象的特征。
* ResNet是大模型诞生的必要条件之一，大模型需要非常多的层次才可以学习到庞大的数据中蕴含的深层逻辑和知识，而这就需要残差连接来让模型参数充分训练，并且减少计算量。即将原来的模型的复杂度降低。
